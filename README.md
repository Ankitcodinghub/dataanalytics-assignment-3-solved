# dataanalytics-assignment-3-solved



**<span style='color:red'>TO GET THIS SOLUTION VISIT:</span>** https://www.ankitcodinghub.com/product/dataanalytics-assignment-3-solved/

<h2>Description</h2>



<div class="kk-star-ratings kksr-auto kksr-align-center kksr-valign-top" data-payload="{&quot;align&quot;:&quot;center&quot;,&quot;id&quot;:&quot;101701&quot;,&quot;slug&quot;:&quot;default&quot;,&quot;valign&quot;:&quot;top&quot;,&quot;ignore&quot;:&quot;&quot;,&quot;reference&quot;:&quot;auto&quot;,&quot;class&quot;:&quot;&quot;,&quot;count&quot;:&quot;2&quot;,&quot;legendonly&quot;:&quot;&quot;,&quot;readonly&quot;:&quot;&quot;,&quot;score&quot;:&quot;5&quot;,&quot;starsonly&quot;:&quot;&quot;,&quot;best&quot;:&quot;5&quot;,&quot;gap&quot;:&quot;4&quot;,&quot;greet&quot;:&quot;Rate this product&quot;,&quot;legend&quot;:&quot;5\/5 - (2 votes)&quot;,&quot;size&quot;:&quot;24&quot;,&quot;title&quot;:&quot;DataAnalytics Assignment 3 Solved&quot;,&quot;width&quot;:&quot;138&quot;,&quot;_legend&quot;:&quot;{score}\/{best} - ({count} {votes})&quot;,&quot;font_factor&quot;:&quot;1.25&quot;}">
            
<div class="kksr-stars">
    
<div class="kksr-stars-inactive">
            <div class="kksr-star" data-star="1" style="padding-right: 4px">
            

<div class="kksr-icon" style="width: 24px; height: 24px;"></div>
        </div>
            <div class="kksr-star" data-star="2" style="padding-right: 4px">
            

<div class="kksr-icon" style="width: 24px; height: 24px;"></div>
        </div>
            <div class="kksr-star" data-star="3" style="padding-right: 4px">
            

<div class="kksr-icon" style="width: 24px; height: 24px;"></div>
        </div>
            <div class="kksr-star" data-star="4" style="padding-right: 4px">
            

<div class="kksr-icon" style="width: 24px; height: 24px;"></div>
        </div>
            <div class="kksr-star" data-star="5" style="padding-right: 4px">
            

<div class="kksr-icon" style="width: 24px; height: 24px;"></div>
        </div>
    </div>
    
<div class="kksr-stars-active" style="width: 138px;">
            <div class="kksr-star" style="padding-right: 4px">
            

<div class="kksr-icon" style="width: 24px; height: 24px;"></div>
        </div>
            <div class="kksr-star" style="padding-right: 4px">
            

<div class="kksr-icon" style="width: 24px; height: 24px;"></div>
        </div>
            <div class="kksr-star" style="padding-right: 4px">
            

<div class="kksr-icon" style="width: 24px; height: 24px;"></div>
        </div>
            <div class="kksr-star" style="padding-right: 4px">
            

<div class="kksr-icon" style="width: 24px; height: 24px;"></div>
        </div>
            <div class="kksr-star" style="padding-right: 4px">
            

<div class="kksr-icon" style="width: 24px; height: 24px;"></div>
        </div>
    </div>
</div>
                

<div class="kksr-legend" style="font-size: 19.2px;">
            5/5 - (2 votes)    </div>
    </div>
<div class="page" title="Page 1">
<div class="layoutArea">
<div class="column">
Question 1

</div>
</div>
<div class="layoutArea">
<div class="column">
Given the following data, please apply the Fisher linear discriminant method. There are two classes, C1 and

</div>
</div>
<div class="layoutArea">
<div class="column">
a) Comute the mean of the first class μ1, and the mean of the second class mu2.

b) Compute the within class variation Sw = S1 + S2, where S1 and S2 are the variations within C1 and C2, respectively.

c) Find the optimum projection v which can lead to the maximum separation of the projected observations. d) Find the cutoff point 12vTμ1 + 12vTμ2.

e) Given a new observation (5, 3), which class does it belong to?

<div class="page" title="Page 3">
<div class="layoutArea">
<div class="column">
Question 2

In the forensic glass example, we classify the type of the glass shard into six categories based on three predictors. The categories are: WinF, WinNF, Veh, Con Tabl and Head. The three predictors are the mineral concentrations of Na, Mg, and Al. Attached is the R output of the multinomial logistic regression. The R function vglm considers the last group as the baseline category. The estimates of the five intercepts and the estimates of the 15 slopes are provided in the output. The model contains 20 parameters, which are estimated on 214 cases.

</div>
</div>
<div class="layoutArea">
<div class="column">
a) Let pij denote the probability that the ith observation belongs to class j. Formulate the logistic model for the five log odds: logpi1, logpi2 ,logpi3 , logpi4 , logpi5 .

</div>
</div>
<div class="layoutArea">
<div class="column">
pi6 pi6 pi6 pi6 pi6

b) The ith piece of glass shard is obtained and the Na, Mg, Al concentrations are: 0.20, 0.06, and 0.11,

</div>
</div>
<div class="layoutArea">
<div class="column">
respectively. Calculate the probabilities pi1, pi2,pi3, pi4, pi5, and pi6. Based on the predicted class probability, which type of glass does this piece of glass belong to?

<div class="page" title="Page 5">
<div class="layoutArea">
<div class="column">
Question 3

a. In this question, we consider the discrimant analysis method for multivariate normal data. Given C1 , C2 , …, CK classes, we assign the prior probabilities to each class P (Cj ), j = 1, …, K . Given that X belongs to class Cj, the conditional distribution of X is a multivariate normal with the mean μj, and the covariance matrix Σj. Then based on the Bayes formula,

P(C |X) = P(Cj)P(X|Cj)

j 􏰀Kj=1 P(Cj′)P(X|Cj′)

Then we can use P(Cj|X) as the discriminant function. We assign X to class j if P(Cj|X) &gt; P(Cj′|X), for any other classes. As the denominator is a constant which does not depend on j, we can use P(Cj)P(X|Cj) as the discriminant function. Or equivalently we can use logP(X|Cj) + logP(Cj). The discriminant function is denoted by gj(X).

</div>
</div>
<div class="layoutArea">
<div class="column">
gj(X) = logP(X|Cj) + logP(Cj)

= −1(X − μj)T Σ−1(X − μj) − 1log|Σj| + logP(Cj)

</div>
</div>
<div class="layoutArea">
<div class="column">
2j2

Consider the case that Σj = σ2I. In this case, all the predictors are independent with different means and

</div>
</div>
<div class="layoutArea">
<div class="column">
equal variances σ2. Please simplify gj(X) and show that it is a linear function of X.

b. In this example, we have three classes, each is a 2-dim Gaussian distribution, with μ1 = (2, −1)T , μ2 =(4,3)T,μ3 =(2,3)T,Σ1 =Σ2 =Σ3 =2I2 whereI2 isanidentitymatrixofdimension2×2. We assume the priors P (C1 ) = P (C2 ) = 14 , and P (C3 ) = 12 . Let X = (0.5, 0.4)T . Calculate g1 (X ), g2 (X ), and g3(X). Classify the observation X to one of the classes.

<div class="page" title="Page 7">
<div class="layoutArea">
<div class="column">
Question 4

Analyze the student math performance test. Apply the linear discriminant analysis and quadratic discriminant analysis on the dataset. The response variable is ”schoolsup” and the three predictors are ”G1”, ”G2” and ”G3”. Please randomly select 300 observations as the training set and use your two models to predict the default status of the remaining students. Repeat this cross-validation five times and calculate the average misclassification errors of the two models. Which method performs better for this data set, the linear

discriminant analysis or the quadratic discriminant analysis?

<div class="page" title="Page 9">
<div class="layoutArea">
<div class="column">
Question 5

Suppose we have 2-classes observations with p-dimensional predictors. We have samples x1,…,xn, with n1 samples from Class 1 and n2 samples from Class 2. Let v be a unit vector. The projection of sample xi onto a line in direction v is given by the inner product of yi = vT xi.Let μ1 and μ2 be the means of class 1 and class 2. Let μ ̃1 and μ ̃2 be the mean of the projections of class 1 and class 2. Denote the variance of the projected samples of class 1 is S ̃12 = 􏰀xi∈C1 (yi − μ ̃1)2 and the variance of the projected samples of class 2 is S ̃2 = 􏰀xi∈C2 (yi − μ ̃2)2. The Fisher linear discriminant is to project to a direction v which maximizes:

the original samples of class 2 be S2 = 􏰀xi∈C2 (xi − μ2)(xi − μ2)T . Define the within class variation: Sw = S1 + S2

Define the between the class variation: Sb = (μ1 − μ2)(μ1 − μ2)T . Prove the objective function can be simplified as:

J(v)= vTSbv vTSwv

</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
